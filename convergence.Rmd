---
title: "Convergence Statistics"
author: "Karl Hornlund"
date: "August 14, 2018"
output: 
  html_document:
    fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The following is an analysis of samples sizes required to estimate a binary variable using a *95\% Confidence Interval*. In particular: 

*How does the width of a 95% confidence interval narrow as the number of trials increases?*

The goal is to inform decisions choosing a number of trials $N$, such that $N$ is not *unnecessarily large*, while large enough to give appropriate *confidence* in estimates resulting from the trials.


```{r funcs, echo = FALSE, message=FALSE}
library(tidyverse)
library(ggthemes)

# get N samples of binary outcomes with probability p
get_samples <- function(N, p) {
  samples <- sample(x = c(1, 0), size = N, replace = TRUE, prob = c(p, 1-p))
  return(samples)
}

# given a set of sample lists, subset the first N
# samples of each list and compute the average
# confidence interval size
get_width_for_N <- function(N, samples) {
  sample_subset <- data.frame(samples[1:N, ])
  stats <- map_dfr(sample_subset, compute_stats)
  return(mean(stats$size))
}

compute_stats <- function(x) {
  q  <- qnorm(.975) # 95% confidence interval
  N  <- length(x)
  s  <- sd(x)
  mu <- mean(x)
  
  lower <- mu - q * s / sqrt(N)
  upper <- mu + q * s / sqrt(N)
  size <- upper - lower
  
  stats <- list(
    "mu" = mu,
    "sd" = s,
    "N"  = N,
    "lower" = lower,
    "upper" = upper,
    "size" = size
  )
  
  return(stats)
}

get_widths <- function(p, B, runs) {
  samples <- replicate(B, get_samples(max(runs), p))
  sizes <- map(runs, get_width_for_N, samples = samples)
  names(sizes) <- runs
  
  return(sizes)
}
```

```{r execution, echo=FALSE, message=FALSE}
B <- 500 # repeats
probs <- seq(0.50, 0.99, 0.01)
runs <- seq(100, 700, 100)

results.df <- cbind(probs, map_dfr(probs, get_widths, B = B, runs = runs))
names(results.df)[1] <- "P"

widths.df <- results.df %>%
  gather(key = N, value = Width, -P) %>%
  arrange(desc(P))
  
intercepts <- widths.df %>%
  filter(Width < 0.05) %>%
  group_by(N) %>%
  summarise(Intercept = min(P))
```

## Results


### General Trends 

The following shows the expected width of a 95% Confidence Interval, given the probability of a binary outcome $p$, and the number of trials performed $N$.

```{r plot01, echo=FALSE}
widths.df %>%
  ggplot(aes(x = P, y = Width, color = N)) +
  geom_line() +
  scale_color_gdocs() +
  theme_gdocs() +
  labs(
    title = "Width of 95% Confidence Interval",
    x = "Probability of Binary Outcome",
    y = "Width of 95% Confidence Interval",
    color = "Runs"
  )
```

### Intersection with $width = 0.05$

The following shows the number of trials ($N$) required to narrow the Confidence Interval width to below $0.05$, for a given probability $p$. In other words, it shows how the lines in the plot above intersect with $y = 0.05$.

```{r plot02, echo=FALSE}
intercepts %>%
  ggplot(aes(x = as.numeric(N), y = Intercept)) +
  geom_point() +
  geom_line() +
  theme_gdocs() +
  labs(
    title = "Convergence to 0.05 Confidence Interval Width",
    x = "Number of Runs (N)",
    y = "Probability at which Confidence Interval width is 0.05"
  )
```

## Appendix

### Monte Carlo Results

```{r monte-carlo, echo = FALSE}
print.df <- results.df[seq(1, nrow(results.df), by = 5), ]
print(map_dfr(print.df, round, digits = 3))
```


